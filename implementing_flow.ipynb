{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for implementing the Flow algorithm in the Attention structure.\n",
    "\n",
    "Main idea: Given a model, assign as **source** its **class token** embedding at **final layer**. The **sinks** will be the **input tokens**. The Graph will be generated by the matrices $A$ as in the paper:\n",
    "\n",
    "$$\n",
    "A = \\frac{W_{att} + I}{2} \n",
    "$$\n",
    "\n",
    "Plus we have to renormalize (check how normalization is done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/ml_env/miniconda3/envs/venv_ml_env/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Data/ml_env/miniconda3/envs/venv_ml_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import maxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_a_matrices(attentions, discard_ratio, head_fusion):\n",
    "    '''Generates the A matrices as in the paper from the attention layers\n",
    "    '''\n",
    "    a_matrices = []\n",
    "    \n",
    "    for attention in attentions:\n",
    "        # Getting type of fusion of channels\n",
    "        if head_fusion == \"mean\":\n",
    "            attention_heads_fused = attention.mean(axis=1)\n",
    "        elif head_fusion == \"max\":\n",
    "            attention_heads_fused = attention.max(axis=1)[0]\n",
    "        elif head_fusion == \"min\":\n",
    "            attention_heads_fused = attention.min(axis=1)[0]\n",
    "        else:\n",
    "            raise \"Attention head fusion type Not supported\"\n",
    "        \n",
    "        # Drop the lowest attentions, but\n",
    "        # don't drop the class token\n",
    "        flat = attention_heads_fused.view(attention_heads_fused.size(0), -1)\n",
    "        _, indices = flat.topk(int(flat.size(-1)*discard_ratio), -1, False)\n",
    "        indices = indices[indices != 0]\n",
    "        flat[0, indices] = 0\n",
    "        \n",
    "        \n",
    "        I = torch.eye(attention_heads_fused.size(-1))\n",
    "        a = (attention_heads_fused + 1.0*I)/2\n",
    "        \n",
    "        a = a / a.sum(dim=-1)\n",
    "        # a = a / a.sum(dim=-1, keepdim=True) -> verify which one is correct\n",
    "        \n",
    "        a_matrices.append(a)  \n",
    "    \n",
    "    return a_matrices\n",
    "    \n",
    "    \n",
    "def compute_flow(a_matrices, input_node, output_flow, discard_ratio):\n",
    "    '''Compute flow of a single input source\n",
    "    '''\n",
    "    n_tokens = a_matrices[0].size(-1)\n",
    "    n_layers = len(a_matrices)\n",
    "    \n",
    "    n_nodes = n_layers * n_tokens\n",
    "\n",
    "    n_vertices = int((1 - discard_ratio) * n_tokens**2 + 1)\n",
    "\n",
    "    print(n_nodes)\n",
    "    print(n_vertices)\n",
    "\n",
    "    g = maxflow.Graph[float](n_nodes, n_vertices) \n",
    "    nodes = g.add_nodes(n_nodes) \n",
    "\n",
    "    ## Setting first nodes who will be sink\n",
    "\n",
    "    for i in range(n_tokens):\n",
    "        g.add_tedge(nodes[i], 0., output_flow)\n",
    "        \n",
    "    ## Setting final nodes who will be source\n",
    "    source_weights = a_matrices[-1][0, :, input_node]\n",
    "    for idx, node_number in enumerate(range(n_nodes - n_tokens, n_nodes)):\n",
    "        g.add_tedge(nodes[node_number], source_weights[idx], 0)\n",
    "\n",
    "    ## Setting internal nodes\n",
    "\n",
    "    for n_layer, a_matrix in enumerate(a_matrices):\n",
    "        if n_layer == len(a_matrices) - 1: break\n",
    "        \n",
    "        start_node = n_layer * n_tokens\n",
    "        start_node_next = (n_layer + 1) * n_tokens\n",
    "        \n",
    "        for idx_x, node_number in enumerate(range(start_node, start_node + n_tokens)):\n",
    "            weights = a_matrix[0,idx_x,:]\n",
    "            \n",
    "            for idx_y in range(n_tokens):\n",
    "                if idx_y != 0: continue\n",
    "                weight = weights[idx_y]\n",
    "                \n",
    "                if weight == 0: continue\n",
    "                \n",
    "                node_number_next = start_node_next + idx_y\n",
    "                g.add_edge(nodes[node_number], nodes[node_number_next], 0., weight) # next layer points to layer before\n",
    "                \n",
    "    max_flow = g.maxflow()\n",
    "    \n",
    "    return max_flow\n",
    "\n",
    "\n",
    "def compute_all_flows(a_matrices, output_flow, discard_ratio):\n",
    "    '''Compute flow for all sources\n",
    "    '''\n",
    "    n_tokens = a_matrices[0].size(-1)\n",
    "    \n",
    "    mask = torch.Tensor(np.zeros(n_tokens))\n",
    "    \n",
    "    for n_token in range(n_tokens):\n",
    "        mask[n_token] = compute_flow(a_matrices, n_token, output_flow, discard_ratio)\n",
    "        \n",
    "    mask = mask[1:]\n",
    "    \n",
    "    width = int(mask.size(-1)**0.5)\n",
    "    mask = mask.reshape(width, width).numpy()\n",
    "    mask = mask / np.max(mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def flow(attentions, discard_ratio, head_fusion, output_flow=2.):\n",
    "    '''Generates attention flow mask in similar fashion as rollout\n",
    "    '''\n",
    "    \n",
    "    a_matrices = compute_a_matrices(attentions, discard_ratio, head_fusion)\n",
    "    \n",
    "    # must generate mask\n",
    "    mask = compute_all_flows(a_matrices, output_flow, discard_ratio)\n",
    "\n",
    "    # Adjust for output\n",
    "    width = int(mask.size(-1)**0.5)\n",
    "    mask = mask.reshape(width, width).numpy()\n",
    "    mask = mask / np.max(mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "class VITAttentionFlow:\n",
    "    def __init__(self, model, attention_layer_name='attn_drop', head_fusion=\"mean\", discard_ratio=0.9):\n",
    "        self.model = model\n",
    "        self.head_fusion = head_fusion\n",
    "        self.discard_ratio = discard_ratio\n",
    "        \n",
    "        for name, module in self.model.named_modules():\n",
    "            if attention_layer_name in name:\n",
    "                module.register_forward_hook(self.get_attention)\n",
    "\n",
    "        self.attentions = []\n",
    "\n",
    "    def get_attention(self, module, input, output):\n",
    "        self.attentions.append(output.cpu())\n",
    "\n",
    "    def __call__(self, input_tensor):\n",
    "        self.attentions = []\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "        return flow(self.attentions, self.discard_ratio, self.head_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
